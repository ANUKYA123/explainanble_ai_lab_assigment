{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVZZZpcj8VQaAmBl2Rkpz8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52176yeruva/explainable-ai-lab-assignment/blob/main/lab_1_assignment_2176.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySSgFIcAIU6j",
        "outputId": "80c858a9-5bb0-43b2-bb58-41bcf2f242a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Model: Sign-ups = 6.71 + 9.36 * Webinars_Attended\n",
            "Baseline (mean Sign-ups): 14.20\n",
            "\n",
            "   Webinars_Attended  Sign_ups  Predicted       SHAP  Difference  \\\n",
            "0                  0         5   6.714286  -7.485714    1.714286   \n",
            "1                  1        15  16.071429   1.871429    1.071429   \n",
            "2                  2        25  25.428571  11.228571    0.428571   \n",
            "3                  0         8   6.714286  -7.485714   -1.285714   \n",
            "4                  1        18  16.071429   1.871429   -1.928571   \n",
            "\n",
            "    Prediction_Type  \n",
            "0   Over Prediction  \n",
            "1   Over Prediction  \n",
            "2   Over Prediction  \n",
            "3  Under Prediction  \n",
            "4  Under Prediction  \n",
            "\n",
            "Interpretation:\n",
            "- The baseline sign-ups value (average) is 14.20.\n",
            "- The slope coefficient 9.36 indicates that each additional webinar attended is associated with an increase of about 9.36 sign-ups.\n",
            "- SHAP values show how much the webinar attendance changes prediction from the baseline.\n",
            "- Comparing predicted and actual values tells us where the model over or under predicts.\n",
            "\n",
            "Summary Analysis:\n",
            "- The model captures a positive correlation between webinars attended and sign-ups.\n",
            "- Most predictions slightly under-predict actual sign-ups, except for some over-predictions at zero webinars.\n",
            "- The model provides reasonable estimates but could improve with more data for better accuracy.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Dataset\n",
        "data = {\n",
        "    'Webinars_Attended': [0, 1, 2, 0, 1],\n",
        "    'Sign_ups': [5, 15, 25, 8, 18]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Perform Linear Regression Analysis\n",
        "X = df[['Webinars_Attended']]\n",
        "y = df['Sign_ups']\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Coefficients\n",
        "intercept = model.intercept_\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# 2. Calculate Baseline Value (mean of y)\n",
        "baseline = y.mean()\n",
        "\n",
        "# 3. Calculate predicted sign-ups and SHAP values (Predicted - Baseline)\n",
        "df['Predicted'] = model.predict(X)\n",
        "df['SHAP'] = df['Predicted'] - baseline\n",
        "\n",
        "# 4. Confirm Final Prediction = Baseline + SHAP\n",
        "df['Check'] = baseline + df['SHAP']\n",
        "\n",
        "# 5. Compare predicted vs actual sign-ups and classify over/under prediction\n",
        "df['Difference'] = df['Predicted'] - df['Sign_ups']\n",
        "df['Prediction_Type'] = df['Difference'].apply(\n",
        "    lambda x: 'Over Prediction' if x > 0 else ('Under Prediction' if x < 0 else 'Exact'))\n",
        "\n",
        "# Print model summary\n",
        "print(f\"Linear Regression Model: Sign-ups = {intercept:.2f} + {slope:.2f} * Webinars_Attended\")\n",
        "print(f\"Baseline (mean Sign-ups): {baseline:.2f}\\n\")\n",
        "print(df[['Webinars_Attended', 'Sign_ups', 'Predicted', 'SHAP', 'Difference', 'Prediction_Type']])\n",
        "\n",
        "# Interpretation Summary\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"- The baseline sign-ups value (average) is {baseline:.2f}.\")\n",
        "print(f\"- The slope coefficient {slope:.2f} indicates that each additional webinar attended is associated with an increase of about {slope:.2f} sign-ups.\")\n",
        "print(\"- SHAP values show how much the webinar attendance changes prediction from the baseline.\")\n",
        "print(\"- Comparing predicted and actual values tells us where the model over or under predicts.\")\n",
        "\n",
        "print(\"\\nSummary Analysis:\")\n",
        "print(\"- The model captures a positive correlation between webinars attended and sign-ups.\")\n",
        "print(\"- Most predictions slightly under-predict actual sign-ups, except for some over-predictions at zero webinars.\")\n",
        "print(\"- The model provides reasonable estimates but could improve with more data for better accuracy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Dataset\n",
        "data = {\n",
        "    'Webinars': [3, 2, 1, 4, 2],\n",
        "    'Blogs': [5, 3, 4, 2, 1],\n",
        "    'Signups': [60, 45, 40, 55, 35]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Multiple Linear Regression\n",
        "X = df[['Webinars', 'Blogs']]\n",
        "y = df['Signups']\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "\n",
        "# 2. Baseline (mean of sign-ups)\n",
        "baseline = y.mean()\n",
        "\n",
        "# 3. Predictions and SHAP values (feature contribution)\n",
        "df['Predicted'] = model.predict(X)\n",
        "df['SHAP_Webinars'] = coefficients[0] * df['Webinars']\n",
        "df['SHAP_Blogs'] = coefficients[1] * df['Blogs']\n",
        "\n",
        "# Verify prediction reconstruction\n",
        "df['Prediction_Check'] = intercept + df['SHAP_Webinars'] + df['SHAP_Blogs']\n",
        "\n",
        "# 4. Compare predicted vs actual and classify prediction type\n",
        "df['Difference'] = df['Predicted'] - df['Signups']\n",
        "df['Prediction_Type'] = df['Difference'].apply(\n",
        "    lambda x: 'Over Prediction' if x > 0 else ('Under Prediction' if x < 0 else 'Exact'))\n",
        "\n",
        "# Results\n",
        "print(f\"Multiple Linear Regression Model:\")\n",
        "print(f\"Sign-ups = {intercept:.2f} + {coefficients[0]:.2f} * Webinars + {coefficients[1]:.2f} * Blogs\")\n",
        "print(f\"Baseline (mean Sign-ups): {baseline:.2f}\\n\")\n",
        "\n",
        "print(df[['Webinars', 'Blogs', 'Signups', 'Predicted', 'SHAP_Webinars', 'SHAP_Blogs', 'Prediction_Check', 'Difference', 'Prediction_Type']])\n",
        "\n",
        "print(\"\\nInterpretation per record:\")\n",
        "for i, row in df.iterrows():\n",
        "    print(f\"Record {i+1}: Webinars SHAP={row['SHAP_Webinars']:.2f}, Blogs SHAP={row['SHAP_Blogs']:.2f}\")\n",
        "    print(f\"  Predicted Signups: {row['Predicted']:.2f} vs Actual: {row['Signups']} -> {row['Prediction_Type']}\")\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"- Intercept (baseline): {intercept:.2f}.\")\n",
        "print(f\"- Webinars increase sign-ups by {coefficients[0]:.2f} per unit.\")\n",
        "print(f\"- Blogs increase sign-ups by {coefficients[1]:.2f} per unit.\")\n",
        "print(\"- SHAP values show the additive contribution of each feature to the prediction relative to baseline.\")\n",
        "print(\"- Some over- and under-predictions occur, possibly due to data variability or linear model limitations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQzHKgMzLUrN",
        "outputId": "96537674-16e5-40e9-a502-ef1b462b2d4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple Linear Regression Model:\n",
            "Sign-ups = 15.59 + 7.75 * Webinars + 4.27 * Blogs\n",
            "Baseline (mean Sign-ups): 47.00\n",
            "\n",
            "   Webinars  Blogs  Signups  Predicted  SHAP_Webinars  SHAP_Blogs  \\\n",
            "0         3      5       60  60.196078      23.235294   21.372549   \n",
            "1         2      3       45  43.901961      15.490196   12.823529   \n",
            "2         1      4       40  40.431373       7.745098   17.098039   \n",
            "3         4      2       55  55.117647      30.980392    8.549020   \n",
            "4         2      1       35  35.352941      15.490196    4.274510   \n",
            "\n",
            "   Prediction_Check  Difference   Prediction_Type  \n",
            "0         60.196078    0.196078   Over Prediction  \n",
            "1         43.901961   -1.098039  Under Prediction  \n",
            "2         40.431373    0.431373   Over Prediction  \n",
            "3         55.117647    0.117647   Over Prediction  \n",
            "4         35.352941    0.352941   Over Prediction  \n",
            "\n",
            "Interpretation per record:\n",
            "Record 1: Webinars SHAP=23.24, Blogs SHAP=21.37\n",
            "  Predicted Signups: 60.20 vs Actual: 60 -> Over Prediction\n",
            "Record 2: Webinars SHAP=15.49, Blogs SHAP=12.82\n",
            "  Predicted Signups: 43.90 vs Actual: 45 -> Under Prediction\n",
            "Record 3: Webinars SHAP=7.75, Blogs SHAP=17.10\n",
            "  Predicted Signups: 40.43 vs Actual: 40 -> Over Prediction\n",
            "Record 4: Webinars SHAP=30.98, Blogs SHAP=8.55\n",
            "  Predicted Signups: 55.12 vs Actual: 55 -> Over Prediction\n",
            "Record 5: Webinars SHAP=15.49, Blogs SHAP=4.27\n",
            "  Predicted Signups: 35.35 vs Actual: 35 -> Over Prediction\n",
            "\n",
            "Summary:\n",
            "- Intercept (baseline): 15.59.\n",
            "- Webinars increase sign-ups by 7.75 per unit.\n",
            "- Blogs increase sign-ups by 4.27 per unit.\n",
            "- SHAP values show the additive contribution of each feature to the prediction relative to baseline.\n",
            "- Some over- and under-predictions occur, possibly due to data variability or linear model limitations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"diabetes.csv\")\n",
        "\n",
        "target_column = 'Outcome'\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "feature_names = X.columns\n",
        "baseline = y_train.mean()\n",
        "\n",
        "df_test = X_test.copy()\n",
        "df_test['Actual_Outcome'] = y_test\n",
        "df_test['Predicted_Outcome'] = model.predict(X_test)\n",
        "\n",
        "# Calculate SHAP values relative to baseline\n",
        "# SHAP(feature_i) = coefficient_i * (feature_i_value - mean(feature_i in training set))\n",
        "# so SHAP sum + baseline = prediction\n",
        "feature_means = X_train.mean()\n",
        "\n",
        "for i, feature in enumerate(feature_names):\n",
        "    df_test[f'SHAP_{feature}'] = coefficients[i] * (df_test[feature] - feature_means[feature])\n",
        "\n",
        "shap_columns = [f'SHAP_{f}' for f in feature_names]\n",
        "df_test['SHAP_Sum'] = df_test[shap_columns].sum(axis=1)\n",
        "\n",
        "# Verify Prediction = Baseline + SHAP sum\n",
        "df_test['Check_Prediction'] = baseline + df_test['SHAP_Sum']\n",
        "\n",
        "df_test['Difference'] = df_test['Predicted_Outcome'] - df_test['Actual_Outcome']\n",
        "df_test['Prediction_Type'] = df_test['Difference'].apply(\n",
        "    lambda x: 'Over Prediction' if x > 0 else ('Under Prediction' if x < 0 else 'Exact')\n",
        ")\n",
        "\n",
        "print(f\"Multiple Linear Regression Model:\\nOutcome = {intercept:.2f} + sum(coefficients × features)\")\n",
        "for feat, coef in zip(feature_names, coefficients):\n",
        "    print(f\"  {feat}: {coef:.4f}\")\n",
        "\n",
        "print(f\"\\nBaseline (mean Outcome in training set): {baseline:.2f}\\n\")\n",
        "\n",
        "output_cols = ['Actual_Outcome', 'Predicted_Outcome', 'Difference', 'Prediction_Type'] + shap_columns\n",
        "print(df_test[output_cols].head())\n",
        "\n",
        "print(\"\\nInterpretation for first 3 test records:\")\n",
        "for i in range(3):\n",
        "    print(f\"\\nRecord {i+1}:\")\n",
        "    print(f\"  Actual: {df_test.iloc[i]['Actual_Outcome']:.2f}\")\n",
        "    print(f\"  Predicted: {df_test.iloc[i]['Predicted_Outcome']:.2f} ({df_test.iloc[i]['Prediction_Type']})\")\n",
        "    print(f\"  Baseline: {baseline:.2f}\")\n",
        "    print(\"  Feature contributions (SHAP values):\")\n",
        "    for feat in feature_names:\n",
        "        print(f\"    {feat}: {df_test.iloc[i][f'SHAP_{feat}']:.4f}\")\n",
        "    print(f\"  Sum of SHAPs: {df_test.iloc[i]['SHAP_Sum']:.4f}\")\n",
        "    print(f\"  Prediction Check (Baseline + SHAP sum): {df_test.iloc[i]['Check_Prediction']:.4f}\")\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"- Baseline = average Outcome value in training set, serving as the baseline prediction.\")\n",
        "print(\"- SHAP values show how each feature pushes the prediction above or below this baseline for each patient.\")\n",
        "print(\"- The sum of SHAP values plus baseline matches the predicted value exactly.\")\n",
        "print(\"- Positive SHAP values increase predicted outcome; negative values decrease it.\")\n",
        "print(\"- Over- and under-predictions are identified and can be analyzed via SHAP contributions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp9XZIAFOwAf",
        "outputId": "120cd834-fce3-48cd-ec45-3b154594e51f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple Linear Regression Model:\n",
            "Outcome = -0.95 + sum(coefficients × features)\n",
            "  Pregnancies: 0.0105\n",
            "  Glucose: 0.0056\n",
            "  BloodPressure: -0.0023\n",
            "  SkinThickness: 0.0005\n",
            "  Insulin: -0.0003\n",
            "  BMI: 0.0150\n",
            "  DiabetesPedigreeFunction: 0.1113\n",
            "  Age: 0.0065\n",
            "\n",
            "Baseline (mean Outcome in training set): 0.35\n",
            "\n",
            "     Actual_Outcome  Predicted_Outcome  Difference  Prediction_Type  \\\n",
            "668               0           0.335500    0.335500  Over Prediction   \n",
            "324               0           0.238099    0.238099  Over Prediction   \n",
            "624               0           0.151052    0.151052  Over Prediction   \n",
            "690               0           0.240136    0.240136  Over Prediction   \n",
            "473               0           0.481424    0.481424  Over Prediction   \n",
            "\n",
            "     SHAP_Pregnancies  SHAP_Glucose  SHAP_BloodPressure  SHAP_SkinThickness  \\\n",
            "668          0.023630     -0.128755            0.026039            0.006705   \n",
            "324         -0.018243     -0.049885           -0.012739            0.006173   \n",
            "624         -0.018243     -0.072419            0.012352           -0.010854   \n",
            "690          0.044566     -0.078053           -0.024144           -0.010854   \n",
            "473          0.034098      0.085320           -0.046954           -0.010854   \n",
            "\n",
            "     SHAP_Insulin  SHAP_BMI  SHAP_DiabetesPedigreeFunction  SHAP_Age  \n",
            "668     -0.030196  0.030327                      -0.004358  0.065202  \n",
            "324      0.022652  0.055893                      -0.035734 -0.076923  \n",
            "624      0.022652 -0.017797                      -0.034621 -0.076923  \n",
            "690      0.022652 -0.111036                       0.043040  0.007060  \n",
            "473      0.022652 -0.031331                      -0.028836  0.110424  \n",
            "\n",
            "Interpretation for first 3 test records:\n",
            "\n",
            "Record 1:\n",
            "  Actual: 0.00\n",
            "  Predicted: 0.34 (Over Prediction)\n",
            "  Baseline: 0.35\n",
            "  Feature contributions (SHAP values):\n",
            "    Pregnancies: 0.0236\n",
            "    Glucose: -0.1288\n",
            "    BloodPressure: 0.0260\n",
            "    SkinThickness: 0.0067\n",
            "    Insulin: -0.0302\n",
            "    BMI: 0.0303\n",
            "    DiabetesPedigreeFunction: -0.0044\n",
            "    Age: 0.0652\n",
            "  Sum of SHAPs: -0.0114\n",
            "  Prediction Check (Baseline + SHAP sum): 0.3355\n",
            "\n",
            "Record 2:\n",
            "  Actual: 0.00\n",
            "  Predicted: 0.24 (Over Prediction)\n",
            "  Baseline: 0.35\n",
            "  Feature contributions (SHAP values):\n",
            "    Pregnancies: -0.0182\n",
            "    Glucose: -0.0499\n",
            "    BloodPressure: -0.0127\n",
            "    SkinThickness: 0.0062\n",
            "    Insulin: 0.0227\n",
            "    BMI: 0.0559\n",
            "    DiabetesPedigreeFunction: -0.0357\n",
            "    Age: -0.0769\n",
            "  Sum of SHAPs: -0.1088\n",
            "  Prediction Check (Baseline + SHAP sum): 0.2381\n",
            "\n",
            "Record 3:\n",
            "  Actual: 0.00\n",
            "  Predicted: 0.15 (Over Prediction)\n",
            "  Baseline: 0.35\n",
            "  Feature contributions (SHAP values):\n",
            "    Pregnancies: -0.0182\n",
            "    Glucose: -0.0724\n",
            "    BloodPressure: 0.0124\n",
            "    SkinThickness: -0.0109\n",
            "    Insulin: 0.0227\n",
            "    BMI: -0.0178\n",
            "    DiabetesPedigreeFunction: -0.0346\n",
            "    Age: -0.0769\n",
            "  Sum of SHAPs: -0.1959\n",
            "  Prediction Check (Baseline + SHAP sum): 0.1511\n",
            "\n",
            "Summary:\n",
            "- Baseline = average Outcome value in training set, serving as the baseline prediction.\n",
            "- SHAP values show how each feature pushes the prediction above or below this baseline for each patient.\n",
            "- The sum of SHAP values plus baseline matches the predicted value exactly.\n",
            "- Positive SHAP values increase predicted outcome; negative values decrease it.\n",
            "- Over- and under-predictions are identified and can be analyzed via SHAP contributions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Q4.1 Load and prepare data\n",
        "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
        "df['Final_Score'] = df[['math score','reading score','writing score']].mean(axis=1)\n",
        "X = pd.get_dummies(df.drop(columns=['math score','reading score','writing score','Final_Score']), drop_first=True)\n",
        "y = df['Final_Score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Q4.1 Fit Multiple Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "coefficients = model.coef_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Q4.2 Baseline value\n",
        "baseline = y_train.mean()\n",
        "\n",
        "# Q4.3 SHAP values (relative to baseline)\n",
        "feature_means = X_train.mean()\n",
        "df_test = X_test.copy()\n",
        "df_test['Actual_Final_Score'] = y_test\n",
        "df_test['Predicted_Final_Score'] = model.predict(X_test)\n",
        "for i, feature in enumerate(feature_names):\n",
        "    df_test[f\"SHAP_{feature}\"] = coefficients[i] * (df_test[feature] - feature_means[feature])\n",
        "shap_cols = [f\"SHAP_{f}\" for f in feature_names]\n",
        "df_test['SHAP_Sum'] = df_test[shap_cols].sum(axis=1)\n",
        "\n",
        "# Q4.4 Verify prediction decomposition\n",
        "df_test['Check_Prediction'] = baseline + df_test['SHAP_Sum']\n",
        "\n",
        "# Q4.5 Compare predictions and classify\n",
        "df_test['Difference'] = df_test['Predicted_Final_Score'] - df_test['Actual_Final_Score']\n",
        "df_test['Prediction_Type'] = df_test['Difference'].apply(\n",
        "    lambda x: 'Over Prediction' if x > 0 else ('Under Prediction' if x < 0 else 'Exact')\n",
        ")\n",
        "\n",
        "# Outputs\n",
        "print(f\"Baseline (Mean Final Score): {baseline:.2f}\")\n",
        "print(\"Coefficients:\")\n",
        "for f, c in zip(feature_names, coefficients):\n",
        "    print(f\"{f}: {c:.4f}\")\n",
        "print(df_test[['Actual_Final_Score','Predicted_Final_Score','Difference','Prediction_Type'] + shap_cols].head())\n",
        "\n",
        "# Q4.5 Interpretation for first 3 students\n",
        "for i in range(3):\n",
        "    print(f\"\\nRecord {i+1}:\")\n",
        "    print(f\"  Actual: {df_test.iloc[i]['Actual_Final_Score']:.2f}\")\n",
        "    print(f\"  Predicted: {df_test.iloc[i]['Predicted_Final_Score']:.2f} ({df_test.iloc[i]['Prediction_Type']})\")\n",
        "    print(f\"  Baseline: {baseline:.2f}\")\n",
        "    for feat in feature_names:\n",
        "        print(f\"    {feat}: {df_test.iloc[i][f'SHAP_{feat}']:.4f}\")\n",
        "    print(f\"  Sum of SHAPs: {df_test.iloc[i]['SHAP_Sum']:.4f}\")\n",
        "    print(f\"  Prediction Check: {df_test.iloc[i]['Check_Prediction']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnpmN_cdO2Xx",
        "outputId": "72b6237d-f46c-448e-cbcb-e1208b88a7b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (Mean Final Score): 68.17\n",
            "Coefficients:\n",
            "gender_male: -4.0919\n",
            "race/ethnicity_group B: -0.1398\n",
            "race/ethnicity_group C: 0.9179\n",
            "race/ethnicity_group D: 3.7809\n",
            "race/ethnicity_group E: 5.9602\n",
            "parental level of education_bachelor's degree: 3.5021\n",
            "parental level of education_high school: -4.6570\n",
            "parental level of education_master's degree: 1.9284\n",
            "parental level of education_some college: -0.8541\n",
            "parental level of education_some high school: -3.2730\n",
            "lunch_standard: 9.2077\n",
            "test preparation course_none: -7.8777\n",
            "     Actual_Final_Score  Predicted_Final_Score  Difference   Prediction_Type  \\\n",
            "521           87.000000              70.522773  -16.477227  Under Prediction   \n",
            "737           64.000000              67.280948    3.280948   Over Prediction   \n",
            "740           75.000000              72.795942   -2.204058  Under Prediction   \n",
            "660           74.666667              56.369159  -18.297507  Under Prediction   \n",
            "411           81.666667              78.496790   -3.169877  Under Prediction   \n",
            "\n",
            "     SHAP_gender_male  SHAP_race/ethnicity_group B  \\\n",
            "521          1.938516                     0.026743   \n",
            "737          1.938516                    -0.113088   \n",
            "740         -2.153339                     0.026743   \n",
            "660         -2.153339                     0.026743   \n",
            "411         -2.153339                     0.026743   \n",
            "\n",
            "     SHAP_race/ethnicity_group C  SHAP_race/ethnicity_group D  \\\n",
            "521                     0.619606                    -0.954667   \n",
            "737                    -0.298329                    -0.954667   \n",
            "740                    -0.298329                     2.826191   \n",
            "660                     0.619606                    -0.954667   \n",
            "411                    -0.298329                    -0.954667   \n",
            "\n",
            "     SHAP_race/ethnicity_group E  \\\n",
            "521                    -0.864231   \n",
            "737                    -0.864231   \n",
            "740                    -0.864231   \n",
            "660                    -0.864231   \n",
            "411                     5.095981   \n",
            "\n",
            "     SHAP_parental level of education_bachelor's degree  \\\n",
            "521                                          -0.420252    \n",
            "737                                          -0.420252    \n",
            "740                                           3.081850    \n",
            "660                                          -0.420252    \n",
            "411                                          -0.420252    \n",
            "\n",
            "     SHAP_parental level of education_high school  \\\n",
            "521                                      0.925571   \n",
            "737                                      0.925571   \n",
            "740                                      0.925571   \n",
            "660                                      0.925571   \n",
            "411                                      0.925571   \n",
            "\n",
            "     SHAP_parental level of education_master's degree  \\\n",
            "521                                         -0.113293   \n",
            "737                                         -0.113293   \n",
            "740                                         -0.113293   \n",
            "660                                         -0.113293   \n",
            "411                                         -0.113293   \n",
            "\n",
            "     SHAP_parental level of education_some college  \\\n",
            "521                                       0.194308   \n",
            "737                                      -0.659795   \n",
            "740                                       0.194308   \n",
            "660                                      -0.659795   \n",
            "411                                      -0.659795   \n",
            "\n",
            "     SHAP_parental level of education_some high school  SHAP_lunch_standard  \\\n",
            "521                                           0.560501             3.188150   \n",
            "737                                           0.560501            -6.019504   \n",
            "740                                           0.560501             3.188150   \n",
            "660                                           0.560501            -6.019504   \n",
            "411                                           0.560501             3.188150   \n",
            "\n",
            "     SHAP_test preparation course_none  \n",
            "521                          -2.747347  \n",
            "737                           5.130351  \n",
            "740                          -2.747347  \n",
            "660                          -2.747347  \n",
            "411                           5.130351  \n",
            "\n",
            "Record 1:\n",
            "  Actual: 87.00\n",
            "  Predicted: 70.52 (Under Prediction)\n",
            "  Baseline: 68.17\n",
            "    gender_male: 1.9385\n",
            "    race/ethnicity_group B: 0.0267\n",
            "    race/ethnicity_group C: 0.6196\n",
            "    race/ethnicity_group D: -0.9547\n",
            "    race/ethnicity_group E: -0.8642\n",
            "    parental level of education_bachelor's degree: -0.4203\n",
            "    parental level of education_high school: 0.9256\n",
            "    parental level of education_master's degree: -0.1133\n",
            "    parental level of education_some college: 0.1943\n",
            "    parental level of education_some high school: 0.5605\n",
            "    lunch_standard: 3.1882\n",
            "    test preparation course_none: -2.7473\n",
            "  Sum of SHAPs: 2.3536\n",
            "  Prediction Check: 70.5228\n",
            "\n",
            "Record 2:\n",
            "  Actual: 64.00\n",
            "  Predicted: 67.28 (Over Prediction)\n",
            "  Baseline: 68.17\n",
            "    gender_male: 1.9385\n",
            "    race/ethnicity_group B: -0.1131\n",
            "    race/ethnicity_group C: -0.2983\n",
            "    race/ethnicity_group D: -0.9547\n",
            "    race/ethnicity_group E: -0.8642\n",
            "    parental level of education_bachelor's degree: -0.4203\n",
            "    parental level of education_high school: 0.9256\n",
            "    parental level of education_master's degree: -0.1133\n",
            "    parental level of education_some college: -0.6598\n",
            "    parental level of education_some high school: 0.5605\n",
            "    lunch_standard: -6.0195\n",
            "    test preparation course_none: 5.1304\n",
            "  Sum of SHAPs: -0.8882\n",
            "  Prediction Check: 67.2809\n",
            "\n",
            "Record 3:\n",
            "  Actual: 75.00\n",
            "  Predicted: 72.80 (Under Prediction)\n",
            "  Baseline: 68.17\n",
            "    gender_male: -2.1533\n",
            "    race/ethnicity_group B: 0.0267\n",
            "    race/ethnicity_group C: -0.2983\n",
            "    race/ethnicity_group D: 2.8262\n",
            "    race/ethnicity_group E: -0.8642\n",
            "    parental level of education_bachelor's degree: 3.0818\n",
            "    parental level of education_high school: 0.9256\n",
            "    parental level of education_master's degree: -0.1133\n",
            "    parental level of education_some college: 0.1943\n",
            "    parental level of education_some high school: 0.5605\n",
            "    lunch_standard: 3.1882\n",
            "    test preparation course_none: -2.7473\n",
            "  Sum of SHAPs: 4.6268\n",
            "  Prediction Check: 72.7959\n"
          ]
        }
      ]
    }
  ]
}